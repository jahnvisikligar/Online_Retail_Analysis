Jahnvi Sikligar

# Kaggle's Predict Future Sales solution report

## Introduction
This report summarizes my attempt to solve the "Predict Future Sales" competition hosted by Kaggle.
 
The report includes the following sections:

* [Competition overview](#competition-overview)
* [Solution description](#solution-description)
    * [Input data](#input-data)
    * [Initial ideas & challenges](#initial-ideas--challenges)
    * [Exploratory data analysis](#exploratory-data-analysis)
    * [Evaluation / Validation](#evaluation--validation)
    * [Preprocessing & Feature Engineering](#preprocessing--feature-engineering)
        * [Preprocessing](#preprocessing)
        ** [Results](#results)
* [Summary](#summary)
 
## Dataset Overview
The task in the competition is to predict monthly sales for a combination of items and shops.
Competitors are provided with daily sales data for certain shops and items. The evaluation metric
for the competition is Root Mean Squared Error (RMSE).

For more information, see <https://www.kaggle.com/c/competitive-data-science-predict-future-sales>.

## Solution description

#### Solution note
The solution described in this report is rather a fast-paced one. Therefore, it is not focused on stuff that is usually heavily explored in
competitions, namely:

* Extensive feature selection & engineering
* Hyperparameter tuning
* Complex ensemble modeling

Instead, my main goal was to firstly obtain a reasonably good result, and then to explore some approaches that
I thought are novel and not explored by other competitors (at least according to competition kernels/discussions).

### Input data
There are 6 files provided by the competition organizer:

* sales_train.csv - daily historical sales data from January 2013 to October 2015.
* test.csv - the test set with item/shop combinations from November 2015, for which sales have to be predicted
* sample_submission.csv - a sample submission file in the correct format
* items.csv - supplementary information about the items
* item_categories.csv - supplementary information about the items categories
* shops.csv- supplementary information about the shops

### Initial ideas & challenges
The first thing to consider is the best way to process the datasets in order to make successful predictions. Since the
training data is a daily based time series, and the test data is monthly-based, several options came to my mind:

1. Data granularity
    1. Daily based training / daily based prediction / aggregation of predictions to monthly format
    1. Monthly based training by training data aggregation / monthly predictions
2. Observations ordering
    1. Classic approach - neglect the order and train as independent observations
    1. Time series approach - sequence based algorithms (ARIMA, RNNs)
    
Every option has some benefits and drawbacks. I decided not to pursue with daily data approach,
because that would require artificially creating days for the test set and then aggregating them back to monthly sales. 
Doesn't seem like a perfectly reasonable approach. Additionally, creating a proper validation setup would also be challenging.

I decided to go with monthly-aggregated non-sequenced approach, so basically the simplest one.

I then experimented more with time-series based approach which yielded pretty good results.

### Exploratory data analysis
I performed some basic EDA to check if the data looks reasonable and there are no obvious errors.

The most important insight I got from EDA was that test set has combinations of all shop/items for a month, 
so the train data has to be processed accordingly in order to obtain proper validation setup.

Some additional interesting facts are the following:

* The sales trend is getting lower every year
* The most expensive item sold was a software licence pack with over 500 licences
* The most frequently sold item is a plastic bag
* The item with most varying price is a credit card payment (or a gift card, I'm not 100% sure)

##### Sales for each year
![Sales for each year](figures/sales-through-year.png)

#### Total sales by shop by year
![Sales by shop by year](figures/sales_by_shop_by_year.png)

The full EDA report is available as a [Jupyter Notebook](../eda/basic_datasets_overview.ipynb)
or [HTML file](../eda/basic_datasets_overview.html) (there are some interactive plots not 
shown here).

### Evaluation / Validation
Since the competition data is a time series, the observations are not independent, as is usually assumed in classic
problems. Therefore, a standard random hold-out/cross-validation setup would not be proper here, as it would yield biased results.
What is needed is a time aware splitting procedure.

For validating the models built, I implemented two time aware validation procedures:

* Simple holdout - the faster method for quick validation. I performed training on `X` months, then I performed
validation on the consecutive month. E.g. training: Jan 2015 - Sep 2015, validation: Oct 2015.
* Time aware cross validation - more extensive validation, where train set width and test set width (in months)  has to
be specified, as well as the number of iterations. The training/validation is then performed similarly to the method above,
but repeated many times for different date ranges. This one reports more detailed information about estimated evaluation metric.

The implementation of the validation procedures is available at [../modeling/model_validation.py](../modeling/model_validation.py).

### Preprocessing & Feature Engineering
I implemented the preprocessing/feature engineering procedure in Spark Scala. The code is available at
[../scala/preprocess_data.scala](../scala/preprocess_data.scala).

#### Preprocessing
The most important preprocessing steps were:

* aggregating the data from the daily basis to monthly basis
* extending the training set to contain all item/shop combinations per month
* filling test data and combining it with training data for feature engineering process

I also performed some standard stuff like year/month extraction, etc. The rest of the processing is contained in Feature
Engineering section.

## Results
The summary of the results I obtained look as follows:

| Method        | Public leaderboard score           |
| ------------- |-------------:|
| Initial xgboost      | 1.10619 |
| xgboost + engineered features | 0.94416 |
| xgboost + eng feats + dense feats | 0.92882 |
| PyTorch embedding net | 0.90933 |
| Best xgb and Best PyTorch Mean* | 0.90326 |
| RNN simple embedding | 0.86097 |

## Performance improvements
Although the initial dataset was pretty small, after extending it with all items/shops combinations and new features I
started running into memory/speed problems. I used the following technologies to work around this:

* Spark Scala (also useful for standalone applications!)
* Using parquet file format to move data around
* xgboost trained on GPU
* running neural nets training on GPU (kind of obvious improvement)

## Summary
Working on this competition was pretty fun, I reminded myself/learned some stuff about working with time series datasets.

Finally, my current position in the competition after implementing the RNN is 17th. I'm aware I made lots of
submissions so there's a possibility of leaderboard overfit.

I believe I could improve even more with some competition-typical stuff (hyperparameter tuning, ensembles, etc.)

![Kaggle Place](figures/kaggle.png)
